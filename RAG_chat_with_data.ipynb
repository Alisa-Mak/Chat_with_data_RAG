{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "62b685c1-fe44-4f01-b9e3-5808cf10752f",
      "metadata": {
        "id": "62b685c1-fe44-4f01-b9e3-5808cf10752f"
      },
      "source": [
        "# Chat With Your Data\n",
        "\n",
        "## Solution: Implement a Vector Store and Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bed94b7-d5da-4c5b-a812-25ecbb1601a6",
      "metadata": {
        "id": "6bed94b7-d5da-4c5b-a812-25ecbb1601a6"
      },
      "source": [
        "# Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "603889ff-e355-4c9e-929a-45e8150aa0f7",
      "metadata": {
        "id": "603889ff-e355-4c9e-929a-45e8150aa0f7",
        "outputId": "7764652a-da39-4476-c1e9-5dae16c3ae5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.13-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.10/site-packages (from openai) (4.4.0)\n",
            "Collecting distro<2,>=1.7.0 (from openai)\n",
            "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.10/site-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.10/site-packages (from openai) (1.3.1)\n",
            "Collecting tqdm>4 (from openai)\n",
            "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions<5,>=4.7 in /home/codespace/.local/lib/python3.10/site-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Downloading openai-1.35.13-py3-none-any.whl (328 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.5/328.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tqdm, distro, openai\n",
            "\u001b[33m  WARNING: The script tqdm is installed in '/usr/local/python/3.10.13/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script distro is installed in '/usr/local/python/3.10.13/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script openai is installed in '/usr/local/python/3.10.13/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed distro-1.9.0 openai-1.35.13 tqdm-4.66.4\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "759ae117-0aa2-4c09-b5bd-7ce1e106ada2",
      "metadata": {
        "id": "759ae117-0aa2-4c09-b5bd-7ce1e106ada2",
        "outputId": "a3b76e11-56a0-4ba2-be57-09ac49c318b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "\u001b[33m  WARNING: The script dotenv is installed in '/usr/local/python/3.10.13/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed python-dotenv-1.0.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd511c5a",
      "metadata": {
        "id": "dd511c5a",
        "outputId": "018d6826-7e43-4b47-b4c4-e7879a8c3b6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.2.7)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.12 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain) (0.2.18)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain) (0.1.85)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.12->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /home/codespace/.local/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.12->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /home/codespace/.local/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /home/codespace/.local/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.12->langchain) (3.0.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca531938",
      "metadata": {
        "id": "ca531938",
        "outputId": "0f85a4f2-b520-4f46-b7ac-2ebf8af9b2b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.1.16-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.17 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain-openai) (0.2.18)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.32.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain-openai) (1.35.13)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /home/codespace/.local/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.17->langchain-openai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.17->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.17->langchain-openai) (0.1.85)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /home/codespace/.local/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.17->langchain-openai) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.17->langchain-openai) (2.8.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.17->langchain-openai) (8.5.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.4.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/codespace/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.12.2)\n",
            "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai)\n",
            "  Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /home/codespace/.local/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /home/codespace/.local/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.17->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.17->langchain-openai) (3.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.17->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.17->langchain-openai) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.0.7)\n",
            "Downloading langchain_openai-0.1.16-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m775.1/775.1 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: regex, tiktoken, langchain-openai\n",
            "Successfully installed langchain-openai-0.1.16 regex-2024.5.15 tiktoken-0.7.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a1839e2",
      "metadata": {
        "id": "4a1839e2",
        "outputId": "93802de7-b772-49b4-8b5e-df28cbd3be7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /home/codespace/.local/lib/python3.10/site-packages (from pypdf) (4.12.2)\n",
            "Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-4.2.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69c527ad",
      "metadata": {
        "id": "69c527ad",
        "outputId": "99357fc6-768b-4359-edd3-135f86ac1695"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.10/site-packages (from faiss-cpu) (24.1)\n",
            "Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0.post1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f9fcee4",
      "metadata": {
        "id": "5f9fcee4",
        "outputId": "20a5747a-ab87-4c7b-9566-b08e2fc5b20f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchainhub\n",
            "  Downloading langchainhub-0.1.20-py3-none-any.whl.metadata (659 bytes)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /home/codespace/.local/lib/python3.10/site-packages (from langchainhub) (24.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from langchainhub) (2.32.3)\n",
            "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
            "  Downloading types_requests-2.32.0.20240712-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2->langchainhub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2->langchainhub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests<3,>=2->langchainhub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2->langchainhub) (2024.7.4)\n",
            "Downloading langchainhub-0.1.20-py3-none-any.whl (5.0 kB)\n",
            "Downloading types_requests-2.32.0.20240712-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: types-requests, langchainhub\n",
            "Successfully installed langchainhub-0.1.20 types-requests-2.32.0.20240712\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install langchainhub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npjtn2z55rIH",
        "outputId": "3b13548b-eb15-4a9b-98d5-293e2168ccd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.7-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /home/codespace/.local/lib/python3.10/site-packages (from langchain-community) (6.0.1)\n",
            "Collecting SQLAlchemy<3,>=1.4 (from langchain-community)\n",
            "  Downloading SQLAlchemy-2.0.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
            "  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting langchain<0.3.0,>=0.2.7 (from langchain-community)\n",
            "  Downloading langchain-0.2.7-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting langchain-core<0.3.0,>=0.2.12 (from langchain-community)\n",
            "  Downloading langchain_core-0.2.18-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.0 (from langchain-community)\n",
            "  Downloading langsmith-0.1.85-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting numpy<2,>=1 (from langchain-community)\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from langchain-community) (8.5.0)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
            "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
            "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
            "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
            "Collecting async-timeout<5.0,>=4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
            "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.7->langchain-community)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting pydantic<3,>=1 (from langchain<0.3.0,>=0.2.7->langchain-community)\n",
            "  Downloading pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.12->langchain-community)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /home/codespace/.local/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.12->langchain-community) (24.1)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain-community)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2024.7.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /home/codespace/.local/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.12.2)\n",
            "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain-community)\n",
            "  Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /home/codespace/.local/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.12->langchain-community) (3.0.0)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain-community)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.20.1 (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain-community)\n",
            "  Downloading pydantic_core-2.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.2.7-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain-0.2.7-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.6/983.6 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.18-py3-none-any.whl (366 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m366.3/366.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.1.85-py3-none-any.whl (127 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading SQLAlchemy-2.0.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
            "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.0/616.0 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.9/423.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: pydantic-core, orjson, numpy, mypy-extensions, multidict, marshmallow, jsonpatch, greenlet, frozenlist, async-timeout, annotated-types, yarl, typing-inspect, SQLAlchemy, pydantic, aiosignal, langsmith, dataclasses-json, aiohttp, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.0\n",
            "    Uninstalling numpy-2.0.0:\n",
            "      Successfully uninstalled numpy-2.0.0\n",
            "\u001b[33m  WARNING: The script f2py is installed in '/usr/local/python/3.10.13/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script langsmith is installed in '/usr/local/python/3.10.13/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script langchain-server is installed in '/usr/local/python/3.10.13/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed SQLAlchemy-2.0.31 aiohttp-3.9.5 aiosignal-1.3.1 annotated-types-0.7.0 async-timeout-4.0.3 dataclasses-json-0.6.7 frozenlist-1.4.1 greenlet-3.0.3 jsonpatch-1.33 langchain-0.2.7 langchain-community-0.2.7 langchain-core-0.2.18 langchain-text-splitters-0.2.2 langsmith-0.1.85 marshmallow-3.21.3 multidict-6.0.5 mypy-extensions-1.0.0 numpy-1.26.4 orjson-3.10.6 pydantic-2.8.2 pydantic-core-2.20.1 typing-inspect-0.9.0 yarl-1.9.4\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install langchain-community"
      ],
      "id": "npjtn2z55rIH"
    },
    {
      "cell_type": "markdown",
      "id": "a2191b2b-67cd-4294-8c08-8b05f858b9fc",
      "metadata": {
        "id": "a2191b2b-67cd-4294-8c08-8b05f858b9fc"
      },
      "source": [
        "# Load PDF documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "519d6515",
      "metadata": {
        "id": "519d6515",
        "outputId": "a2818eac-c4fc-4422-d45b-389549f5df91"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ignoring wrong pointing object 6 0 (offset 0)\n",
            "Ignoring wrong pointing object 8 0 (offset 0)\n",
            "Ignoring wrong pointing object 12 0 (offset 0)\n",
            "Ignoring wrong pointing object 21 0 (offset 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ignoring wrong pointing object 6 0 (offset 0)\n",
            "Ignoring wrong pointing object 8 0 (offset 0)\n",
            "Ignoring wrong pointing object 18 0 (offset 0)\n",
            "Ignoring wrong pointing object 6 0 (offset 0)\n",
            "Ignoring wrong pointing object 8 0 (offset 0)\n",
            "Ignoring wrong pointing object 18 0 (offset 0)\n",
            "Ignoring wrong pointing object 6 0 (offset 0)\n",
            "Ignoring wrong pointing object 8 0 (offset 0)\n",
            "Ignoring wrong pointing object 18 0 (offset 0)\n",
            "Ignoring wrong pointing object 6 0 (offset 0)\n",
            "Ignoring wrong pointing object 8 0 (offset 0)\n",
            "Ignoring wrong pointing object 18 0 (offset 0)\n",
            "Ignoring wrong pointing object 6 0 (offset 0)\n",
            "Ignoring wrong pointing object 8 0 (offset 0)\n",
            "Ignoring wrong pointing object 18 0 (offset 0)\n"
          ]
        }
      ],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "# Load PDF\n",
        "loaders = [\n",
        "    PyPDFLoader(\"../Data/botanical.pdf\"),\n",
        "    PyPDFLoader(\"../Data/astronomical.pdf\"),\n",
        "    PyPDFLoader(\"../Data/biological.pdf\"),\n",
        "    PyPDFLoader(\"../Data/cosmological.pdf\"),\n",
        "    PyPDFLoader(\"../Data/culinary.pdf\"),\n",
        "    PyPDFLoader(\"../Data/pharmaceutical.pdf\")\n",
        "]\n",
        "\n",
        "pages = []\n",
        "\n",
        "for loader in loaders:\n",
        "    pages.extend(loader.load())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "af6d4c53",
        "outputId": "1f876e55-9c6c-4390-83e4-81ab12207a3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(docs)"
      ],
      "id": "af6d4c53"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36d06d6b",
        "outputId": "9864fb10-ec04-47fd-c49d-42e8f718ac67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Botanical Section Botanixum Sectiorum Arcanix \n",
            " A peculiar plant with spiraling leaves and vibrant blue flowers that seem to emit a faint glow in moonlight. • Holoris spiralis: In lumine lunae, flores azuri magni brillant. • Radices mysticae: Radices intortae terram quaerunt, lumina nocturna sequentes. • Usus: Extractum florae noctem illuminat, mentem serenat.  Luminaflora Spiralis Luminaflora Spiralis thrives under the moon's tender gaze, where its spiraling leaves and vibrant blue petals unfol\n"
          ]
        }
      ],
      "source": [
        "print(docs[0].page_content[:500])"
      ],
      "id": "36d06d6b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4a234d8c",
        "outputId": "0eaf7253-ea66-487c-8baf-588ca6a0948e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content=\"Botanical Section Botanixum Sectiorum Arcanix \\n A peculiar plant with spiraling leaves and vibrant blue flowers that seem to emit a faint glow in moonlight. • Holoris spiralis: In lumine lunae, flores azuri magni brillant. • Radices mysticae: Radices intortae terram quaerunt, lumina nocturna sequentes. • Usus: Extractum florae noctem illuminat, mentem serenat.  Luminaflora Spiralis Luminaflora Spiralis thrives under the moon's tender gaze, where its spiraling leaves and vibrant blue petals unfold in a mesmerizing dance of light. Believed by ancient scholars to bridge the earthly realm with the ethereal, these plants radiate a soft luminescence, guiding lost travelers through the darkest nights. Mystics and poets claim that merely being in the presence of Luminaflora can soothe troubled thoughts and illuminate the path to inner peace.   The roots of Luminaflora Spiralis are as intriguing as its blooms. Entwining deeply within the earth, they seek not water, but moonlight that filters through the soil, a phenomenon that baffles even the most learned botanists. The plant's affinity for lunar rays is reflected in its growth cycle, with each phase of the moon bringing about subtle changes in its luminescence and petal orientation. This unique symbiosis with the moon makes Luminaflora a subject of endless fascination.  In medicinal practices, extracts from Luminaflora Spiralis are highly valued for their illuminating properties. Alchemists concoct potions that harness the plant's glow, claiming such elixirs can light up one's inner darkness, dispelling \\n\", metadata={'source': '../Data/botanical.pdf', 'page': 0})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs[0]"
      ],
      "id": "4a234d8c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b801f4a4-db2c-44d3-89d1-d86d052b23e4",
        "outputId": "125e86a9-3d7b-4cf2-c074-ebd056d4f119"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content='4 microcosm of the universe, capable of profound transformation. The text likely explores themes of purification, renewal, and the harmonization of bodily humors, providing a window into the spiritual beliefs and practices that accompanied ancient medicine. This holistic approach highlights the interconnectedness of body, mind, and cosmos in the pursuit of health and longevity.   ', metadata={'source': '../Data/pharmaceutical.pdf', 'page': 3})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs[23]"
      ],
      "id": "b801f4a4-db2c-44d3-89d1-d86d052b23e4"
    },
    {
      "cell_type": "markdown",
      "id": "d045afab-761b-43be-9aa4-145fcfb09904",
      "metadata": {
        "id": "d045afab-761b-43be-9aa4-145fcfb09904"
      },
      "source": [
        "# Split PDF documents into chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdd67ee4",
      "metadata": {
        "id": "fdd67ee4"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator=\"\\n\",\n",
        "    chunk_size=1000, #LLMs have a linit on num of character they can digest\n",
        "    chunk_overlap=150, #chankas may overlap to preserve context\n",
        "    length_function=len #calc len by number of characters\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a18866b9",
      "metadata": {
        "id": "a18866b9"
      },
      "outputs": [],
      "source": [
        "docs = text_splitter.split_documents(pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af6206ad",
      "metadata": {
        "id": "af6206ad",
        "outputId": "537a8f85-f505-41aa-df2a-0ba7d1394ca1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c60017d-f427-47f2-bd08-a4f9e9db6d6c",
      "metadata": {
        "id": "8c60017d-f427-47f2-bd08-a4f9e9db6d6c"
      },
      "source": [
        "# Convert chunks to embeddings and store in FAISS vector database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aaee8ff-3ab2-419e-b879-7f3a78e0367a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file"
      ],
      "id": "6aaee8ff-3ab2-419e-b879-7f3a78e0367a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e0bc507-958b-4cab-a50f-1e0408ed9896"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY=os.environ['OPENAI_API_KEY']"
      ],
      "id": "8e0bc507-958b-4cab-a50f-1e0408ed9896"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7373ef94-cd06-4e92-bafe-ba7c032f4232",
      "metadata": {
        "id": "7373ef94-cd06-4e92-bafe-ba7c032f4232"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY, model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39e0f3c4-5981-4fad-8c81-0969b2f4d34f",
      "metadata": {
        "id": "39e0f3c4-5981-4fad-8c81-0969b2f4d34f",
        "outputId": "5e91baab-3ad0-4330-9d92-7d32df977953"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "vectordb = FAISS.from_documents(docs, embeddings_model)\n",
        "print(vectordb.index.ntotal)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cafecdae-eaf9-471f-b69d-9b1c3ac0b9d2",
      "metadata": {
        "id": "cafecdae-eaf9-471f-b69d-9b1c3ac0b9d2"
      },
      "source": [
        "# Persist the vector database to disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0788aef1-0fe8-4205-ba3d-741bb5cf392a",
      "metadata": {
        "id": "0788aef1-0fe8-4205-ba3d-741bb5cf392a"
      },
      "outputs": [],
      "source": [
        "vectordb.save_local(\"../faiss_index\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL--sXfb77bt"
      },
      "source": [
        "# Load vector database from disk"
      ],
      "id": "UL--sXfb77bt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvXsHIsS77bt"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "\n",
        "db = FAISS.load_local(\"../faiss_index\",\n",
        "                      OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY, model=\"text-embedding-3-small\"),\n",
        "                      allow_dangerous_deserialization=True)"
      ],
      "id": "yvXsHIsS77bt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94184d22-46ad-45e7-8a00-38c298b7e607"
      },
      "source": [
        "## Perform semantic search"
      ],
      "id": "94184d22-46ad-45e7-8a00-38c298b7e607"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82dd70e3-e3ca-4b2d-a238-3ed466e41618"
      },
      "outputs": [],
      "source": [
        "docs = db.similarity_search(\"What are the medicinal insights from the Voynich manuscript?\")"
      ],
      "id": "82dd70e3-e3ca-4b2d-a238-3ed466e41618"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54c02003-3a39-41a7-bbc1-a22b70ca5c3a",
        "outputId": "92795660-54de-42a2-a6f1-5ef35e9bd185"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#length of search results returned\n",
        "len(docs)"
      ],
      "id": "54c02003-3a39-41a7-bbc1-a22b70ca5c3a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ff62b2cc-cebc-43ab-a2ff-d785f40ca73c",
        "outputId": "82707327-96f7-4745-dd32-b6098f086042"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The output is: Detailed anatomical diagrams of mythical beings, possibly used for medicinal or alchemical purposes, with annotations explaining the function of each organ and system.  Anatomical Wonders Intricate Anatomical Details The anatomical diagrams of mythical beings within the Voynich Manuscript offer a fascinating glimpse into what might be ancient medical knowledge intertwined with fantasy. These detailed drawings display the internal structures of creatures that defy familiar biological categories, featuring organs and systems that, while imaginative, are rendered with precise anatomical accuracy. Each illustration is annotated, possibly indicating the functions of various organs and their importance in alchemical or medicinal practices.  Medicinal and Alchemical Connections It is speculated that these diagrams served not only as a compendium of fantastical biology but also as a practical guide for medicinal and alchemical uses. The organs of these mythical creatures might have been believed to possess magical properties, useful in the preparation of potions or remedies. \n",
            "\n",
            "The metadata is {'source': '../Data/biological.pdf', 'page': 1} \n",
            "\n",
            "\n",
            "The output is: An array of mysterious herbs, each with unique properties, depicted with precise botanical detail, possibly indicating their medicinal uses. Herbae mysteriosae, curativis proprietatibus plenae, in manuscripto depictae. Herbal Remedies Diverse Medicinal Properties The Herbal Remedies section of the manuscript is a colorful compendium of various herbs, each illustrated with remarkable detail, suggesting their use in treating ailments. These plants are not just botanically accurate; they seem to carry specific annotations about their healing properties, whether it's soothing pain, curing infections, or enhancing vitality. The detailed depictions serve as a bridge between ancient botanical knowledge and the mysterious lore surrounding herbal medicine.  Cultural and Historical Significance The herbs depicted often have a dual role in both culinary and medicinal practices, indicating their importance across various cultures and epochs. These illustrations may provide insights into the dietary and health practices of the time, revealing how herbs were integral to daily life and survival. The manuscript possibly doubles as a practical guide and a pharmacopeial treasure, preserving knowledge that might have otherwise been lost through the ages.  Pharmacological Applications The annotations likely include recipes for concoctions and mixtures, detailing ratios and preparation methods that. \n",
            "\n",
            "The metadata is {'source': '../Data/pharmaceutical.pdf', 'page': 0} \n",
            "\n",
            "\n",
            "The output is: Detailed drawings of herbal brews and potions, each with specific effects, such as enhancing stamina or curing maladies.  Infusiones herbarum ad vires augendas et morbos sanandos. Herbal Brews and Potions Herbal Mastery This page details the preparation of various herbal brews and potions, each carefully crafted to enhance health, vitality, or even spiritual well-being. The illustrations provide a detailed look at the herbs used, their proportions, and the methods of preparation, from simple infusions to complex concoctions requiring precise timing and conditions. Each potion is associated with specific effects, such as boosting energy, calming nerves, or curing diseases.  Alchemy of Flavors The potions blend the alchemy of flavors with practical pharmacology, embodying the ancient belief in the power of plants to affect body and mind. This section might reveal the manuscript's deeper layers, where culinary practice meets mysticism, and each brew is as much a spiritual ritual as a physical remedy. The cryptic annotations could hint at lost knowledge of herbal properties, passed down through generations of healers.  Cultural and Medicinal Insights Beyond their immediate use, these brews offer insights into the cultural attitudes towards healing and magic. The. \n",
            "\n",
            "The metadata is {'source': '../Data/culinary.pdf', 'page': 1} \n",
            "\n",
            "\n",
            "The output is: 3 in alchemy or witchcraft. Their inclusion in the manuscript could hint at a broader narrative of how such plants were perceived and used in spiritual or transformational practices, revealing a layer of cultural mystique and the interplay between science and superstition.. \n",
            "\n",
            "The metadata is {'source': '../Data/pharmaceutical.pdf', 'page': 2} \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_output(docs)"
      ],
      "id": "ff62b2cc-cebc-43ab-a2ff-d785f40ca73c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat with data config"
      ],
      "metadata": {
        "id": "yRu_TTFHwm85"
      },
      "id": "yRu_TTFHwm85"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solution consists of 3 main parts\n",
        "1. **Retriever Setup:** The first snippet initializes a retriever that can fetch relevant documents based on a query.\n",
        "2. **History-Aware Retriever Chain:** The second snippet enhances the retriever by adding context-awareness using a language model to reformulate user queries, ensuring they are understandable without prior context.\n",
        "3. **Question-Answer Chain:** The third snippet sets up the final QA system that uses the context provided by the retriever to generate concise answers. It combines the history-aware retriever with the QA chain to form the complete RAG chain."
      ],
      "metadata": {
        "id": "D9-Sq2OCzEQD"
      },
      "id": "D9-Sq2OCzEQD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35b7e3f2-eaba-4fa1-aced-d79431959cd9"
      },
      "source": [
        "## Configure retriever\n",
        "### Use the similarity search capabilities of a vector store to facilitate retrieval\n",
        "\n",
        "This is retriever for a vector database\n",
        "\n",
        "it sets up a retriever to fetch relevant documents from a database (db). The retriever is configured to use similarity-based search and returns the top 6 documents (k=6) that are most similar to a given query."
      ],
      "id": "35b7e3f2-eaba-4fa1-aced-d79431959cd9"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SkQxfFV8ypao"
      },
      "id": "SkQxfFV8ypao"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ec80ca7-918a-4898-b64d-4cee56d8141a"
      },
      "outputs": [],
      "source": [
        "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
      ],
      "id": "1ec80ca7-918a-4898-b64d-4cee56d8141a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc3536c8-60fc-40c1-8265-2249a839db08"
      },
      "source": [
        "## Configure LLM"
      ],
      "id": "cc3536c8-60fc-40c1-8265-2249a839db08"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72e8727d-0efe-495d-b896-fcb3ca9d23ed"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "#initialize the LLM we'll use - OpenAI GPT 3.5 Turbo\n",
        "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo-0125\")"
      ],
      "id": "72e8727d-0efe-495d-b896-fcb3ca9d23ed"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bc0fd64-aa2e-46fe-a2c6-a0b8ca109d76"
      },
      "source": [
        "## Define prompt with conversation history"
      ],
      "id": "6bc0fd64-aa2e-46fe-a2c6-a0b8ca109d76"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb86aa1c"
      },
      "source": [
        "Building Prompt for loading and summerizing the conversations hystory\n",
        "Building Chain to construct the Chat hystory + User input and pass to LLM."
      ],
      "id": "bb86aa1c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "This snippet creates a history-aware retriever chain. The system_prompt defines the task of generating a standalone question from the chat history and the user's latest input. The ChatPromptTemplate is used to structure the input for the language model (LLM). The create_history_aware_retriever function integrates the LLM, the retriever, and the prompt to produce a retriever that can handle context from previous interactions. This allows the system to reformulate questions in a way that they can be understood without requiring prior context."
      ],
      "metadata": {
        "id": "7B-w48kVy10o"
      },
      "id": "7B-w48kVy10o"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "732ea316-19cb-435f-b822-fb0647925980"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import create_history_aware_retriever\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "system_prompt = \"\"\"Given the chat history and a recent user question \\\n",
        "generate a new standalone question \\\n",
        "that can be understood without the chat history. Do NOT answer the question, \\\n",
        "just reformulate it if needed or otherwise return it as is.\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "#generate Q&A chain\n",
        "#takes a list of documents, formats them into a prompt, and passes prompt to the LLM\n",
        "retriever_with_history = create_history_aware_retriever(\n",
        "    llm, retriever, prompt\n",
        ")"
      ],
      "id": "732ea316-19cb-435f-b822-fb0647925980"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f05940ef-89cd-4cc5-86e3-9a27f00f94a9"
      },
      "source": [
        "## Perform question answering"
      ],
      "id": "f05940ef-89cd-4cc5-86e3-9a27f00f94a9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c79f88f-5924-4f52-ab0e-3825e16b2be7"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \\\n",
        "Use the following pieces of retrieved context to answer the question. \\\n",
        "If you don't know the answer, just say that you don't know. \\\n",
        "Use three sentences maximum and keep the answer concise.\\\n",
        "\n",
        "{context}\"\"\"\n",
        "\n",
        "qa_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", qa_system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "#generate Q&A chain, that excepts the retrieve context, along with a conversation hystory and query to generate the answer\n",
        "#create_stuff_documents_chain - takes a list of documents, formats them into a prompt, and passes prompt to al LLM\n",
        "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
        "\n",
        "# building a chain: retriever_with_history - retrieves the Vector DB, question_answer_chain - Q&A chain\n",
        "rag_chain = create_retrieval_chain(retriever_with_history, question_answer_chain)"
      ],
      "id": "5c79f88f-5924-4f52-ab0e-3825e16b2be7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Triggering the cahin, watch chatting with data in action"
      ],
      "metadata": {
        "id": "1FVc8mwfx21F"
      },
      "id": "1FVc8mwfx21F"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b0088c4-b593-404e-a9d5-36649862efe2",
        "outputId": "f9a93bc6-82fb-492e-a971-9b2340dcbba9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aetherfloris Ventus is a celestial plant with petals lighter than air, appearing to float freely, nurtured by the whispers of the clouds and winds. Its stem is nearly invisible but surprisingly strong, leading the petals in a delicate dance with the breeze. In alchemy, its essence is believed to bestow the gift of lightness and freedom upon those who partake.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "chat_history = []\n",
        "\n",
        "question = \"What is Aetherfloris Ventus?\"\n",
        "\n",
        "#ai_msg_1 - answer from our prompt\n",
        "ai_msg_1 = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
        "\n",
        "#we then add the prompt answer to the hystory\n",
        "chat_history.extend([HumanMessage(content=question), ai_msg_1[\"answer\"]])\n",
        "\n",
        "print(ai_msg_1[\"answer\"])"
      ],
      "id": "2b0088c4-b593-404e-a9d5-36649862efe2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b75d4d60-4b6b-49c6-a876-0a98bb2fbf5a",
        "outputId": "b83010e8-7dce-480d-cba1-cd51890dffd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A single drop of Aetherfloris Ventus can lift the spirits, freeing the mind from earthly burdens, encouraging thoughts to soar and dreams to take flight. It induces levity in both body and mind, allowing one to experience weightlessness and a sense of freedom. The true nature of Aetherfloris Ventus remains elusive, holding the mysteries of the natural world waiting to be discovered.\n"
          ]
        }
      ],
      "source": [
        "second_question = \"What does a single drop of it do?\"\n",
        "\n",
        "ai_msg_2 = rag_chain.invoke({\"input\": second_question, \"chat_history\": chat_history})\n",
        "print(ai_msg_2[\"answer\"])"
      ],
      "id": "b75d4d60-4b6b-49c6-a876-0a98bb2fbf5a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67bfb493-0c2c-454d-8328-b83aed28406c",
        "outputId": "87e574c8-727d-4490-a711-ce9ba4ef70d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aetherfloris Ventus and Noctis Umbraherba are both unique and mysterious plants with distinct characteristics. Aetherfloris Ventus is a celestial plant with petals lighter than air, nurtured by the whispers of the clouds and winds, while Noctis Umbraherba is a dark, shadowy plant thriving in the absence of light, with leaves darker than the deepest night. Both plants have enigmatic qualities and are sought after for their mystical properties in different realms such as alchemy and botany.\n"
          ]
        }
      ],
      "source": [
        "third_question = \"How does it compare to Noctis Umbraherba?\"\n",
        "ai_msg_3 = rag_chain.invoke({\"input\": third_question, \"chat_history\": chat_history})\n",
        "print(ai_msg_3[\"answer\"])"
      ],
      "id": "67bfb493-0c2c-454d-8328-b83aed28406c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2b60c6b-57bc-44da-9706-0060095635e3",
        "outputId": "387e1dbe-d853-436e-f7e8-e92b6a10548f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Yes, the Biological section of the Voynich Manuscript is significant as it provides intricate anatomical details of mythical beings, possibly reflecting ancient medical knowledge and alchemical practices. The annotated diagrams offer insights into the functions of fantastical organs and systems, possibly used in medicinal or alchemical preparations. These illustrations blend scientific observation with imaginative speculation, inviting further research into how ancient civilizations perceived biology and the body.\n"
          ]
        }
      ],
      "source": [
        "fourth_question = \"Do you think the Biological section of the Voynich Manuscript is important?\"\n",
        "ai_msg_4 = rag_chain.invoke({\"input\": fourth_question, \"chat_history\": chat_history})\n",
        "print(ai_msg_4[\"answer\"])"
      ],
      "id": "e2b60c6b-57bc-44da-9706-0060095635e3"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}